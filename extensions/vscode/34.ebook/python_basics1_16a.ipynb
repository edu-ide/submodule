{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ 2ê¶Œ 6ì¥: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ì…ë¬¸\n",
    "\n",
    "## ğŸ“Œ ëª©ì°¨\n",
    "16.1 ë¨¸ì‹ ëŸ¬ë‹ ê°œë… ë° ê¸°ë³¸ ì›ë¦¬  \n",
    "16.2 scikit-learnì„ ì‚¬ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹  \n",
    "16.3 ë”¥ëŸ¬ë‹ ê¸°ì´ˆ  \n",
    "16.4 TensorFlowì™€ PyTorch í™œìš©  \n",
    "\n",
    "## 16.1 ë¨¸ì‹ ëŸ¬ë‹ì˜ í•µì‹¬ ê°œë…\n",
    "\n",
    "### âœ… 16.1.1 ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜\n",
    "1. **ì§€ë„ í•™ìŠµ**\n",
    "   - ë¶„ë¥˜(Classification)\n",
    "   - íšŒê·€(Regression)\n",
    "\n",
    "2. **ë¹„ì§€ë„ í•™ìŠµ**\n",
    "   - êµ°ì§‘í™”(Clustering)\n",
    "   - ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)\n",
    "\n",
    "3. **ê°•í™” í•™ìŠµ**\n",
    "   - ë³´ìƒ ê¸°ë°˜ í•™ìŠµ\n",
    "   - í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©\n",
    "\n",
    "### âœ… 16.1.2 ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤\n",
    "1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬\n",
    "2. ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ\n",
    "3. í‰ê°€ ë° ìµœì í™”\n",
    "4. ì˜ˆì¸¡ ë° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MLProject:\n",
    "    \"\"\"ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        \n",
    "    def prepare_data(self, X, y, test_size=0.2):\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \"\"\"\n",
    "        # ë°ì´í„° ë¶„í• \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2 ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "### âœ… 16.2.1 ë¶„ë¥˜ ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class ClassificationModel(MLProject):\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy:.4f}\")\n",
    "        print(\"\\në¶„ë¥˜ ë³´ê³ ì„œ:\")\n",
    "        print(report)\n",
    "        \n",
    "        return accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… 16.2.2 íšŒê·€ ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class RegressionModel(MLProject):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = LinearRegression()\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"í‰ê·  ì œê³± ì˜¤ì°¨: {mse:.4f}\")\n",
    "        print(f\"RÂ² ì ìˆ˜: {r2:.4f}\")\n",
    "        \n",
    "        return mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3 ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬í˜„\n",
    "\n",
    "### âœ… 16.3.1 TensorFlowë¥¼ ì‚¬ìš©í•œ ì‹ ê²½ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class DeepLearningModel:\n",
    "    \"\"\"ë”¥ëŸ¬ë‹ ëª¨ë¸ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        self.model = Sequential([\n",
    "            Dense(64, activation='relu', input_dim=input_dim),\n",
    "            Dropout(0.2),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def train(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {loss:.4f}\")\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}\")\n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì‹¤ìŠµ í”„ë¡œì íŠ¸: ì¢…í•© ë¨¸ì‹ ëŸ¬ë‹ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml_project():\n",
    "    \"\"\"ì¢…í•© ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    # ë°ì´í„° ìƒì„±\n",
    "    from sklearn.datasets import make_classification\n",
    "    X, y = make_classification(\n",
    "        n_samples=1000,\n",
    "        n_features=20,\n",
    "        n_classes=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸\n",
    "    print(\"=== ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ===\")\n",
    "    clf = ClassificationModel()\n",
    "    X_train, X_test, y_train, y_test = clf.prepare_data(X, y)\n",
    "    clf.train(X_train, y_train)\n",
    "    clf.evaluate(X_test, y_test)\n",
    "    \n",
    "    # ë”¥ëŸ¬ë‹ ëª¨ë¸\n",
    "    print(\"\\n=== ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ===\")\n",
    "    dl_model = DeepLearningModel(input_dim=20, num_classes=2)\n",
    "    dl_model.train(X_train, y_train)\n",
    "    dl_model.evaluate(X_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_ml_project()"
   ]
  }

 ]
}