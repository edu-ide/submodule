# 6.5 실습 프로젝트: 종합 머신러닝 시스템

이 섹션에서는 지금까지 학습한 머신러닝과 딥러닝 개념을 모두 활용하여 실제 데이터에 적용해 볼 수 있는 종합 프로젝트를 구현합니다.

## ✅ 6.5.1 종합 머신러닝 파이프라인 구현

```python
def run_ml_project():
    """종합 머신러닝 프로젝트 실행"""
    # 데이터 생성
    from sklearn.datasets import make_classification
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_classes=2,
        random_state=42
    )
    
    # 분류 모델
    print("=== 분류 모델 학습 ===")
    clf = ClassificationModel()
    X_train, X_test, y_train, y_test = clf.prepare_data(X, y)
    clf.train(X_train, y_train)
    clf.evaluate(X_test, y_test)
    
    # 딥러닝 모델
    print("\n=== 딥러닝 모델 학습 ===")
    dl_model = DeepLearningModel(input_dim=20, num_classes=2)
    dl_model.train(X_train, y_train)
    dl_model.evaluate(X_test, y_test)

if __name__ == '__main__':
    run_ml_project()
```

## ✅ 6.5.2 감성 분석 프로젝트

텍스트 데이터에 대한 감성 분석 모델을 구현하는 프로젝트입니다.

```python
def sentiment_analysis_project():
    """영화 리뷰 감성 분석 프로젝트"""
    try:
        import tensorflow as tf
        from tensorflow.keras.preprocessing.text import Tokenizer
        from tensorflow.keras.preprocessing.sequence import pad_sequences
        import numpy as np
        import pandas as pd
        
        # 모의 영화 리뷰 데이터 생성
        reviews = [
            "이 영화는 정말 훌륭했습니다. 연기와 스토리 모두 완벽했어요.",
            "지루하고 예측 가능한 스토리라인. 시간 낭비였습니다.",
            "배우들의 연기가 인상적이었고 영상미도 뛰어났습니다.",
            "전체적으로 실망스러운 영화. 기대했던 것보다 훨씬 못했어요.",
            "감동적인 스토리와 멋진 음악이 어우러진 명작입니다.",
            "너무 길고 지루했어요. 중간에 졸기도 했습니다.",
            "올해 본 영화 중 최고였습니다. 강력 추천합니다.",
            "스토리는 약했지만 특수효과는 놀라웠습니다.",
            "완전히 시간 낭비였어요. 보지 않는 것을 추천합니다.",
            "흥미롭고 독창적인 스토리로 끝까지 몰입해서 봤습니다."
        ]
        
        # 긍정(1)과 부정(0) 레이블
        labels = [1, 0, 1, 0, 1, 0, 1, 0, 0, 1]
        
        # 전처리: 텍스트 토큰화
        tokenizer = Tokenizer(num_words=1000, oov_token="<OOV>")
        tokenizer.fit_on_texts(reviews)
        
        # 단어를 정수 인덱스로 변환
        sequences = tokenizer.texts_to_sequences(reviews)
        
        # 패딩으로 시퀀스 길이 통일
        max_length = 30
        padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')
        
        # 데이터셋 구성
        X = np.array(padded_sequences)
        y = np.array(labels)
        
        # 훈련/테스트 분할
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # 모델 구성 (LSTM 사용)
        model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=1000, output_dim=16, input_length=max_length),
            tf.keras.layers.LSTM(32),
            tf.keras.layers.Dense(24, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        
        # 모델 컴파일
        model.compile(
            loss='binary_crossentropy',
            optimizer='adam',
            metrics=['accuracy']
        )
        
        # 모델 요약
        model.summary()
        
        # 모델 학습
        history = model.fit(
            X_train, y_train,
            epochs=50,
            validation_data=(X_test, y_test),
            verbose=1
        )
        
        # 모델 평가
        loss, accuracy = model.evaluate(X_test, y_test)
        print(f"\n테스트 정확도: {accuracy:.4f}")
        
        # 새로운 리뷰로 예측
        new_reviews = [
            "정말 재미있고 감동적인 영화였습니다!",
            "최악의 영화. 돈과 시간이 아깝습니다.",
            "배우들의 연기는 좋았지만 스토리가 약했어요."
        ]
        
        # 새 리뷰 전처리
        new_sequences = tokenizer.texts_to_sequences(new_reviews)
        new_padded = pad_sequences(new_sequences, maxlen=max_length, padding='post')
        
        # 예측
        predictions = model.predict(new_padded)
        
        print("\n새 리뷰 감성 분석 결과:")
        for i, review in enumerate(new_reviews):
            sentiment = "긍정적" if predictions[i][0] > 0.5 else "부정적"
            confidence = predictions[i][0] if predictions[i][0] > 0.5 else 1 - predictions[i][0]
            print(f"리뷰: {review}")
            print(f"감성: {sentiment} (확신도: {confidence:.4f})\n")
        
        return model, history
        
    except ImportError:
        print("필요한 라이브러리가 설치되어 있지 않습니다.")
        print("다음을 설치하세요: pip install tensorflow pandas scikit-learn")
        return None, None
```

## ✅ 6.5.3 이미지 분류 프로젝트

합성곱 신경망(CNN)을 사용하여 이미지 분류 모델을 구현하는 프로젝트입니다.

```python
def image_classification_project():
    """이미지 분류 프로젝트"""
    try:
        import tensorflow as tf
        from tensorflow.keras.datasets import cifar10
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
        from tensorflow.keras.utils import to_categorical
        import numpy as np
        import matplotlib.pyplot as plt
        
        # CIFAR-10 데이터셋 로드
        (X_train, y_train), (X_test, y_test) = cifar10.load_data()
        
        # 클래스 이름
        class_names = ['비행기', '자동차', '새', '고양이', '사슴', '개', '개구리', '말', '배', '트럭']
        
        # 데이터 전처리
        X_train = X_train.astype('float32') / 255.0
        X_test = X_test.astype('float32') / 255.0
        
        # 레이블 원-핫 인코딩
        y_train_one_hot = to_categorical(y_train, 10)
        y_test_one_hot = to_categorical(y_test, 10)
        
        # CNN 모델 구성
        model = Sequential([
            # 첫 번째 합성곱 블록
            Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Dropout(0.25),
            
            # 두 번째 합성곱 블록
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Dropout(0.25),
            
            # 완전 연결 계층
            Flatten(),
            Dense(512, activation='relu'),
            Dropout(0.5),
            Dense(10, activation='softmax')
        ])
        
        # 모델 컴파일
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # 모델 요약
        model.summary()
        
        # 모델 학습
        history = model.fit(
            X_train, y_train_one_hot,
            batch_size=64,
            epochs=10,
            validation_data=(X_test, y_test_one_hot),
            verbose=1
        )
        
        # 모델 평가
        loss, accuracy = model.evaluate(X_test, y_test_one_hot)
        print(f"\n테스트 정확도: {accuracy:.4f}")
        
        # 예측 결과 시각화
        def plot_predictions(model, X, y_true, class_names, num_images=5):
            # 무작위 이미지 선택
            indices = np.random.choice(len(X), num_images, replace=False)
            
            # 예측
            predictions = model.predict(X[indices])
            predicted_classes = np.argmax(predictions, axis=1)
            true_classes = y_true[indices].flatten()
            
            # 이미지 시각화
            plt.figure(figsize=(15, 3))
            for i, idx in enumerate(indices):
                plt.subplot(1, num_images, i + 1)
                plt.imshow(X[idx])
                plt.title(f"실제: {class_names[true_classes[i]]}\n예측: {class_names[predicted_classes[i]]}")
                plt.axis('off')
            plt.tight_layout()
            plt.show()
        
        # 예측 결과 확인
        plot_predictions(model, X_test, y_test, class_names)
        
        return model, history
        
    except ImportError:
        print("필요한 라이브러리가 설치되어 있지 않습니다.")
        print("다음을 설치하세요: pip install tensorflow matplotlib")
        return None, None
```

## ✅ 6.5.4 추천 시스템 프로젝트

협업 필터링을 사용한 영화 추천 시스템을 구현하는 프로젝트입니다.

```python
def recommendation_system_project():
    """협업 필터링 기반 추천 시스템 프로젝트"""
    try:
        import numpy as np
        import pandas as pd
        from sklearn.metrics.pairwise import cosine_similarity
        
        # 모의 영화 평점 데이터 생성
        users = ['사용자1', '사용자2', '사용자3', '사용자4', '사용자5', '사용자6']
        movies = ['어벤져스', '인터스텔라', '기생충', '매트릭스', '타이타닉', '스타워즈']
        
        # 사용자-영화 평점 행렬 (0: 평가 없음, 1-5: 평점)
        ratings = np.array([
            [5, 4, 0, 5, 1, 0],  # 사용자1의 영화 평점
            [0, 0, 5, 4, 0, 3],  # 사용자2의 영화 평점
            [4, 5, 4, 0, 2, 0],  # 사용자3의 영화 평점
            [0, 3, 0, 3, 4, 5],  # 사용자4의 영화 평점
            [3, 0, 4, 5, 0, 0],  # 사용자5의 영화 평점
            [5, 4, 0, 0, 3, 4]   # 사용자6의 영화 평점
        ])
        
        # 데이터프레임 생성
        df = pd.DataFrame(ratings, index=users, columns=movies)
        print("영화 평점 데이터:")
        print(df)
        
        # 사용자 기반 협업 필터링
        def user_based_recommendation(user_id, df, num_recommendations=3):
            """사용자 기반 협업 필터링"""
            # 사용자 인덱스 가져오기
            user_idx = df.index.get_loc(user_id)
            
            # 평점 행렬 복사
            ratings_matrix = df.values.copy()
            
            # 코사인 유사도 계산
            user_similarity = cosine_similarity(ratings_matrix)
            
            # 자기 자신과의 유사도 제거
            np.fill_diagonal(user_similarity, 0)
            
            # 현재 사용자의 유사도 점수
            user_similarity_scores = user_similarity[user_idx]
            
            # 아직 평가하지 않은 영화 찾기
            unrated_movies = ratings_matrix[user_idx] == 0
            
            # 예측 평점 계산
            weighted_ratings = np.zeros(len(df.columns))
            similarity_sum = np.zeros(len(df.columns))
            
            for other_user in range(len(df)):
                # 자기 자신은 건너뛰기
                if other_user == user_idx:
                    continue
                
                # 유사도 점수
                similarity = user_similarity_scores[other_user]
                
                # 가중 평점 계산
                for movie_idx in range(len(df.columns)):
                    if unrated_movies[movie_idx] and ratings_matrix[other_user, movie_idx] > 0:
                        weighted_ratings[movie_idx] += similarity * ratings_matrix[other_user, movie_idx]
                        similarity_sum[movie_idx] += similarity
            
            # 최종 예측 평점 계산
            predicted_ratings = np.zeros(len(df.columns))
            for i in range(len(df.columns)):
                if similarity_sum[i] > 0:
                    predicted_ratings[i] = weighted_ratings[i] / similarity_sum[i]
            
            # 이미 평가한 영화의 예측 점수는 0으로 설정
            predicted_ratings[~unrated_movies] = 0
            
            # 추천 영화 선정
            movie_indices = np.argsort(predicted_ratings)[::-1]
            
            recommendations = []
            for idx in movie_indices:
                if predicted_ratings[idx] > 0:
                    recommendations.append({
                        '영화': df.columns[idx],
                        '예측 평점': predicted_ratings[idx]
                    })
                
                if len(recommendations) >= num_recommendations:
                    break
            
            return recommendations
        
        # 아이템 기반 협업 필터링
        def item_based_recommendation(user_id, df, num_recommendations=3):
            """아이템 기반 협업 필터링"""
            # 영화-영화 유사도 행렬 계산
            item_similarity = cosine_similarity(df.values.T)
            
            # 사용자가 평가한 영화 찾기
            user_ratings = df.loc[user_id].values
            rated_items = user_ratings > 0
            
            # 예측 평점 계산
            predicted_ratings = np.zeros(len(df.columns))
            
            for i in range(len(df.columns)):
                # 이미 평가한 영화는 건너뛰기
                if rated_items[i]:
                    continue
                
                # 현재 영화와 다른 영화들의 유사도
                similarities = item_similarity[i]
                
                # 가중치와 유사도 합 계산
                weighted_sum = 0
                similarity_sum = 0
                
                for j in range(len(df.columns)):
                    if rated_items[j]:
                        weighted_sum += similarities[j] * user_ratings[j]
                        similarity_sum += similarities[j]
                
                # 예측 평점 계산
                if similarity_sum > 0:
                    predicted_ratings[i] = weighted_sum / similarity_sum
            
            # 추천 영화 선정
            movie_indices = np.argsort(predicted_ratings)[::-1]
            
            recommendations = []
            for idx in movie_indices:
                if predicted_ratings[idx] > 0:
                    recommendations.append({
                        '영화': df.columns[idx],
                        '예측 평점': predicted_ratings[idx]
                    })
                
                if len(recommendations) >= num_recommendations:
                    break
            
            return recommendations
        
        # 사용자 기반 추천 결과
        user_recommendations = user_based_recommendation('사용자1', df)
        print("\n사용자 기반 추천 결과 (사용자1):")
        for rec in user_recommendations:
            print(f"{rec['영화']} (예측 평점: {rec['예측 평점']:.2f})")
        
        # 아이템 기반 추천 결과
        item_recommendations = item_based_recommendation('사용자1', df)
        print("\n아이템 기반 추천 결과 (사용자1):")
        for rec in item_recommendations:
            print(f"{rec['영화']} (예측 평점: {rec['예측 평점']:.2f})")
        
        return df, user_recommendations, item_recommendations
    
    except ImportError:
        print("필요한 라이브러리가 설치되어 있지 않습니다.")
        print("다음을 설치하세요: pip install pandas scikit-learn")
        return None, None, None
```

## ✅ 6.5.5 다음 단계: 머신러닝 프로젝트 확장하기

머신러닝 프로젝트를 더 발전시키기 위한 방법들을 소개합니다.

1. **모델 배포하기**
   - Flask 또는 FastAPI를 사용하여 웹 API 구축
   - TensorFlow Serving 또는 TorchServe로 모델 서빙
   - 도커 컨테이너화 및 쿠버네티스 배포

2. **추가 모델 개선하기**
   - 하이퍼파라미터 최적화(Hyperparameter Optimization)
   - 앙상블 방법(Ensemble Methods) 적용
   - 교차 검증(Cross-validation) 활용

3. **대규모 데이터 처리하기**
   - 분산 학습 구현(예: Horovod, TensorFlow Distributed)
   - 빅데이터 도구 통합(예: Spark와 함께 사용)
   - 데이터 파이프라인 최적화

4. **자동화된 머신러닝 파이프라인 구축하기**
   - MLflow로 실험 관리
   - Airflow로 워크플로우 자동화
   - CI/CD 파이프라인 구축 