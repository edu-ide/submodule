---

# ğŸ“˜ 2ê¶Œ 5ì¥: ê³ ê¸‰ ì„±ëŠ¥ ìµœì í™” ë° ë³‘ë ¬ í”„ë¡œê·¸ë˜ë°

## ğŸ“Œ ëª©ì°¨
15.1 ë©€í‹°ìŠ¤ë ˆë”©ê³¼ GILì˜ ì´í•´  
15.2 multiprocessingì„ í™œìš©í•œ ë³‘ë ¬ í”„ë¡œê·¸ë˜ë°  
15.3 ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° (asyncio)  
15.4 JIT ì»´íŒŒì¼ëŸ¬ ë° PyPy  
15.5 Cython ë° Numbaë¥¼ í™œìš©í•œ ì„±ëŠ¥ í–¥ìƒ  

## 15.1 ì„±ëŠ¥ ìµœì í™”ì˜ ê¸°ë³¸ ì›ë¦¬

### âœ… 15.1.1 ë³‘ë ¬ ì²˜ë¦¬ì˜ ì¢…ë¥˜
1. **ë©€í‹°ìŠ¤ë ˆë”©**: í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ ì—¬ëŸ¬ ìŠ¤ë ˆë“œ ì‹¤í–‰
2. **ë©€í‹°í”„ë¡œì„¸ì‹±**: ì—¬ëŸ¬ ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
3. **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°**: I/O ì‘ì—…ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬

### âœ… 15.1.2 ì„±ëŠ¥ ìµœì í™” ë„êµ¬
1. **í”„ë¡œíŒŒì¼ë§**: cProfile, line_profiler
2. **ì»´íŒŒì¼ëŸ¬**: Cython, Numba
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: gc, memory_profiler

```python
import threading
import multiprocessing
import time
import asyncio
import aiohttp

class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    @staticmethod
    def cpu_intensive_task(n):
        """CPU ì§‘ì¤‘ì ì¸ ì‘ì—…"""
        return sum(i * i for i in range(n))
    
    @staticmethod
    def io_intensive_task(url):
        """I/O ì§‘ì¤‘ì ì¸ ì‘ì—…"""
        import requests
        return requests.get(url).text
    
    @classmethod
    def run_with_threading(cls, numbers):
        """ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ì‹¤í–‰"""
        threads = []
        results = []
        
        for n in numbers:
            thread = threading.Thread(
                target=lambda: results.append(cls.cpu_intensive_task(n))
            )
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join()
            
        return results
    
    @classmethod
    def run_with_multiprocessing(cls, numbers):
        """ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì‹¤í–‰"""
        with multiprocessing.Pool() as pool:
            return pool.map(cls.cpu_intensive_task, numbers)
    
    @staticmethod
    async def async_fetch(url):
        """ë¹„ë™ê¸° HTTP ìš”ì²­"""
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                return await response.text()
    
    @classmethod
    async def run_with_asyncio(cls, urls):
        """ë¹„ë™ê¸°ë¡œ ì—¬ëŸ¬ URL ì²˜ë¦¬"""
        tasks = [cls.async_fetch(url) for url in urls]
        return await asyncio.gather(*tasks)
```

## 15.2 ê³ ê¸‰ ë³‘ë ¬ ì²˜ë¦¬ ê¸°ë²•

### âœ… 15.2.1 í”„ë¡œì„¸ìŠ¤ í’€ê³¼ ìŠ¤ë ˆë“œ í’€

```python
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor

class ParallelProcessor:
    """ê³ ê¸‰ ë³‘ë ¬ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, max_workers=None):
        self.max_workers = max_workers or multiprocessing.cpu_count()
    
    def process_pool_execution(self, func, items):
        """í”„ë¡œì„¸ìŠ¤ í’€ì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬"""
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(func, items))
        return results
    
    def thread_pool_execution(self, func, items):
        """ìŠ¤ë ˆë“œ í’€ì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬"""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            results = list(executor.map(func, items))
        return results
    
    @staticmethod
    def benchmark(func, *args):
        """ì‹¤í–‰ ì‹œê°„ ì¸¡ì •"""
        start_time = time.time()
        result = func(*args)
        end_time = time.time()
        return result, end_time - start_time
```

## 15.3 ê³ ê¸‰ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°

### âœ… 15.3.1 ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ì™€ ì´ë²¤íŠ¸ ë£¨í”„

```python
class AsyncContextManager:
    """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    
    def __init__(self):
        self.lock = asyncio.Lock()
    
    async def __aenter__(self):
        await self.lock.acquire()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.lock.release()

class AsyncProcessor:
    """ê³ ê¸‰ ë¹„ë™ê¸° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.context = AsyncContextManager()
    
    async def process_with_retry(self, coro, max_retries=3):
        """ì¬ì‹œë„ ê¸°ëŠ¥ì´ ìˆëŠ” ë¹„ë™ê¸° ì²˜ë¦¬"""
        for attempt in range(max_retries):
            try:
                async with self.context:
                    return await coro
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
    
    @staticmethod
    async def gather_with_concurrency(n, *coros):
        """ë™ì‹œì„± ì œí•œì´ ìˆëŠ” ë¹„ë™ê¸° ìˆ˜ì§‘"""
        semaphore = asyncio.Semaphore(n)
        
        async def wrapped_coro(coro):
            async with semaphore:
                return await coro
        
        return await asyncio.gather(
            *(wrapped_coro(c) for c in coros)
        )
```

## 15.4 ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ìµœì í™”

### âœ… 15.4.1 ì½”ë“œ í”„ë¡œíŒŒì¼ë§

```python
import cProfile
import pstats
from line_profiler import LineProfiler

class CodeProfiler:
    """ì½”ë“œ í”„ë¡œíŒŒì¼ë§ í´ë˜ìŠ¤"""
    
    @staticmethod
    def profile_function(func, *args, **kwargs):
        """í•¨ìˆ˜ í”„ë¡œíŒŒì¼ë§"""
        profiler = cProfile.Profile()
        result = profiler.runcall(func, *args, **kwargs)
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative').print_stats(20)
        return result
    
    @staticmethod
    def line_profile(func):
        """ë¼ì¸ë³„ í”„ë¡œíŒŒì¼ë§"""
        lp = LineProfiler()
        wrapped = lp(func)
        
        def profiled_func(*args, **kwargs):
            result = wrapped(*args, **kwargs)
            lp.print_stats()
            return result
        
        return profiled_func
```

## ğŸ¯ ì‹¤ìŠµ í”„ë¡œì íŠ¸

### [ì‹¤ìŠµ 1] ëŒ€ìš©ëŸ‰ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬

```python
def process_large_dataset():
    """ëŒ€ìš©ëŸ‰ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ì˜ˆì œ"""
    # ë°ì´í„° ìƒì„±
    data = [(i, i * 2) for i in range(10**6)]
    
    # ë³‘ë ¬ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = ParallelProcessor()
    
    # ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
    def process_item(item):
        x, y = item
        return x * y + sum(i * i for i in range(1000))
    
    # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì²˜ë¦¬
    results, time_taken = processor.benchmark(
        processor.process_pool_execution,
        process_item,
        data
    )
    
    print(f"ì²˜ë¦¬ ì™„ë£Œ: {len(results):,}ê°œ í•­ëª©")
    print(f"ì†Œìš” ì‹œê°„: {time_taken:.2f}ì´ˆ")
    
    return results
```

---