# 5.5 ì‹¤ìŠµ í”„ë¡œì íŠ¸

## ğŸ¯ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬

```python
def process_large_dataset():
    """ëŒ€ìš©ëŸ‰ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ì˜ˆì œ"""
    # ë°ì´í„° ìƒì„±
    data = [(i, i * 2) for i in range(10**6)]
    
    # ë³‘ë ¬ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = ParallelProcessor()
    
    # ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
    def process_item(item):
        x, y = item
        return x * y + sum(i * i for i in range(1000))
    
    # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì²˜ë¦¬
    results, time_taken = processor.benchmark(
        processor.process_pool_execution,
        process_item,
        data
    )
    
    print(f"ì²˜ë¦¬ ì™„ë£Œ: {len(results):,}ê°œ í•­ëª©")
    print(f"ì†Œìš” ì‹œê°„: {time_taken:.2f}ì´ˆ")
    
    return results
```

## ğŸ¯ ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”

```python
def image_processing_optimization():
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™” í”„ë¡œì íŠ¸"""
    try:
        import numpy as np
        from PIL import Image
        import time
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
        def apply_blur_python(image_data, kernel_size=3):
            """ìˆœìˆ˜ íŒŒì´ì¬ìœ¼ë¡œ ë¸”ëŸ¬ í•„í„° ì ìš© (ëŠë¦¼)"""
            height, width = len(image_data), len(image_data[0])
            result = [[0 for _ in range(width)] for _ in range(height)]
            
            pad = kernel_size // 2
            for i in range(pad, height - pad):
                for j in range(pad, width - pad):
                    # ì»¤ë„ ì˜ì—­ì˜ í‰ê·  ê³„ì‚°
                    sum_val = 0
                    count = 0
                    for ki in range(-pad, pad + 1):
                        for kj in range(-pad, pad + 1):
                            sum_val += image_data[i + ki][j + kj]
                            count += 1
                    result[i][j] = sum_val // count
            
            return result
        
        def apply_blur_numpy(image_array, kernel_size=3):
            """NumPyë¡œ ë¸”ëŸ¬ í•„í„° ì ìš© (ë¹ ë¦„)"""
            from scipy.ndimage import uniform_filter
            return uniform_filter(image_array, size=kernel_size)
        
        # ì„ì˜ ì´ë¯¸ì§€ ë°ì´í„° ìƒì„± (ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ì´ë¯¸ì§€ íŒŒì¼ ë¡œë“œ)
        img_size = 500
        image_data = [[np.random.randint(0, 256) for _ in range(img_size)] for _ in range(img_size)]
        image_array = np.array(image_data, dtype=np.uint8)
        
        # ì„±ëŠ¥ ì¸¡ì • - íŒŒì´ì¬ ë²„ì „
        start = time.time()
        py_result = apply_blur_python(image_data, 3)
        py_time = time.time() - start
        
        # ì„±ëŠ¥ ì¸¡ì • - NumPy ë²„ì „
        start = time.time()
        np_result = apply_blur_numpy(image_array, 3)
        np_time = time.time() - start
        
        print(f"íŒŒì´ì¬ ì²˜ë¦¬ ì‹œê°„: {py_time:.4f}ì´ˆ")
        print(f"NumPy ì²˜ë¦¬ ì‹œê°„: {np_time:.4f}ì´ˆ")
        print(f"ì†ë„ í–¥ìƒ: {py_time / np_time:.1f}ë°°")
        
    except ImportError:
        print("í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install numpy pillow scipy")
```

## ğŸ¯ ì›¹ ìŠ¤í¬ë˜í•‘ ë¹„ë™ê¸° ì²˜ë¦¬

```python
def async_web_scraping():
    """ì›¹ ìŠ¤í¬ë˜í•‘ ë¹„ë™ê¸° ì²˜ë¦¬ í”„ë¡œì íŠ¸"""
    import asyncio
    import aiohttp
    import time
    from bs4 import BeautifulSoup
    import re
    
    # ë™ê¸° ë°©ì‹ ìŠ¤í¬ë˜í•‘
    def sync_scrape(urls):
        """ë™ê¸°ì  ì›¹ ìŠ¤í¬ë˜í•‘"""
        import requests
        
        results = []
        start = time.time()
        
        for url in urls:
            try:
                response = requests.get(url, timeout=10)
                soup = BeautifulSoup(response.text, 'html.parser')
                title = soup.title.string if soup.title else "ì œëª© ì—†ìŒ"
                results.append({"url": url, "title": title})
            except Exception as e:
                results.append({"url": url, "error": str(e)})
        
        elapsed = time.time() - start
        return results, elapsed
    
    # ë¹„ë™ê¸° ë°©ì‹ ìŠ¤í¬ë˜í•‘
    async def async_scrape(urls):
        """ë¹„ë™ê¸°ì  ì›¹ ìŠ¤í¬ë˜í•‘"""
        results = []
        start = time.time()
        
        async def fetch(session, url):
            try:
                async with session.get(url, timeout=10) as response:
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    title = soup.title.string if soup.title else "ì œëª© ì—†ìŒ"
                    return {"url": url, "title": title}
            except Exception as e:
                return {"url": url, "error": str(e)}
        
        async with aiohttp.ClientSession() as session:
            tasks = [fetch(session, url) for url in urls]
            results = await asyncio.gather(*tasks)
        
        elapsed = time.time() - start
        return results, elapsed
    
    # í…ŒìŠ¤íŠ¸ URL ë¦¬ìŠ¤íŠ¸ (ê³µê°œ ì›¹ì‚¬ì´íŠ¸)
    test_urls = [
        "https://www.python.org",
        "https://docs.python.org",
        "https://pypi.org",
        "https://www.wikipedia.org",
        "https://www.github.com"
    ]
    
    # ë™ê¸° ë°©ì‹ í…ŒìŠ¤íŠ¸
    sync_results, sync_time = sync_scrape(test_urls)
    
    # ë¹„ë™ê¸° ë°©ì‹ í…ŒìŠ¤íŠ¸
    async_results, async_time = asyncio.run(async_scrape(test_urls))
    
    # ê²°ê³¼ ì¶œë ¥
    print("[ ë™ê¸° ë°©ì‹ ê²°ê³¼ ]")
    for result in sync_results:
        if "error" in result:
            print(f"{result['url']}: ì˜¤ë¥˜ - {result['error']}")
        else:
            print(f"{result['url']}: {result['title']}")
    print(f"ì†Œìš” ì‹œê°„: {sync_time:.2f}ì´ˆ")
    
    print("\n[ ë¹„ë™ê¸° ë°©ì‹ ê²°ê³¼ ]")
    for result in async_results:
        if "error" in result:
            print(f"{result['url']}: ì˜¤ë¥˜ - {result['error']}")
        else:
            print(f"{result['url']}: {result['title']}")
    print(f"ì†Œìš” ì‹œê°„: {async_time:.2f}ì´ˆ")
    print(f"ì†ë„ í–¥ìƒ: {sync_time / async_time:.1f}ë°°")
```

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” ì¢…í•© í”„ë¡œì íŠ¸

```python
def comprehensive_optimization_project():
    """ì„±ëŠ¥ ìµœì í™” ì¢…í•© í”„ë¡œì íŠ¸"""
    
    class DataProcessor:
        """ë°ì´í„° ì²˜ë¦¬ ë° ìµœì í™” í´ë˜ìŠ¤"""
        
        def __init__(self, data_size=1000000):
            self.data_size = data_size
            self.generate_data()
        
        def generate_data(self):
            """ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„±"""
            import random
            self.data = [random.randint(1, 1000) for _ in range(self.data_size)]
        
        def process_sequential(self):
            """ìˆœì°¨ì  ì²˜ë¦¬"""
            result = []
            for item in self.data:
                if item % 2 == 0:  # ì§ìˆ˜ë§Œ ì²˜ë¦¬
                    result.append(self._transform_item(item))
            return result
        
        def process_functional(self):
            """í•¨ìˆ˜í˜• ì²˜ë¦¬"""
            return list(map(self._transform_item, filter(lambda x: x % 2 == 0, self.data)))
        
        def process_comprehension(self):
            """ì»´í”„ë¦¬í—¨ì…˜ ì²˜ë¦¬"""
            return [self._transform_item(item) for item in self.data if item % 2 == 0]
        
        def process_parallel(self):
            """ë³‘ë ¬ ì²˜ë¦¬"""
            from concurrent.futures import ProcessPoolExecutor
            
            # ì§ìˆ˜ë§Œ í•„í„°ë§
            even_data = [item for item in self.data if item % 2 == 0]
            
            # ë³‘ë ¬ ì²˜ë¦¬
            with ProcessPoolExecutor() as executor:
                return list(executor.map(self._transform_item, even_data))
        
        def _transform_item(self, item):
            """ì•„ì´í…œ ë³€í™˜ (ê³„ì‚° ì§‘ì•½ì  ì‘ì—…)"""
            return sum(i * i for i in range(item))
    
    # ì‹¤í–‰ ë° ë¹„êµ
    import time
    
    processor = DataProcessor(data_size=100000)
    
    # ìˆœì°¨ì  ì²˜ë¦¬
    start = time.time()
    seq_result = processor.process_sequential()
    seq_time = time.time() - start
    
    # í•¨ìˆ˜í˜• ì²˜ë¦¬
    start = time.time()
    func_result = processor.process_functional()
    func_time = time.time() - start
    
    # ì»´í”„ë¦¬í—¨ì…˜ ì²˜ë¦¬
    start = time.time()
    comp_result = processor.process_comprehension()
    comp_time = time.time() - start
    
    # ë³‘ë ¬ ì²˜ë¦¬
    start = time.time()
    par_result = processor.process_parallel()
    par_time = time.time() - start
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ì²˜ë¦¬ëœ í•­ëª© ìˆ˜: {len(seq_result):,}")
    print(f"ìˆœì°¨ì  ì²˜ë¦¬ ì‹œê°„: {seq_time:.4f}ì´ˆ")
    print(f"í•¨ìˆ˜í˜• ì²˜ë¦¬ ì‹œê°„: {func_time:.4f}ì´ˆ (ì†ë„ í–¥ìƒ: {seq_time/func_time:.1f}ë°°)")
    print(f"ì»´í”„ë¦¬í—¨ì…˜ ì²˜ë¦¬ ì‹œê°„: {comp_time:.4f}ì´ˆ (ì†ë„ í–¥ìƒ: {seq_time/comp_time:.1f}ë°°)")
    print(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œê°„: {par_time:.4f}ì´ˆ (ì†ë„ í–¥ìƒ: {seq_time/par_time:.1f}ë°°)")
    
    # ê²€ì¦ (ëª¨ë“  ê²°ê³¼ê°€ ë™ì¼í•œì§€ í™•ì¸)
    results_match = (
        len(seq_result) == len(func_result) == len(comp_result) == len(par_result) and
        all(seq_result[i] == func_result[i] == comp_result[i] == par_result[i]
            for i in range(min(10, len(seq_result))))
    )
    
    print(f"ê²°ê³¼ ì¼ì¹˜ ì—¬ë¶€: {'ì˜ˆ' if results_match else 'ì•„ë‹ˆì˜¤'}")
```

## ğŸ¯ ì¶”ê°€ ë„ì „ ê³¼ì œ

1. **ë¶„ì‚° ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„**: Dask ë˜ëŠ” Rayë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ë¨¸ì‹ ì— ê±¸ì¹œ ë¶„ì‚° ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„í•´ë³´ê¸°

2. **GPU ê°€ì†í™”**: CUDAì™€ í•¨ê»˜ Numbaë¥¼ ì‚¬ìš©í•˜ì—¬ GPUë¡œ ê°€ì†í™”ëœ ê³„ì‚° ìˆ˜í–‰í•˜ê¸°

3. **ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸**: ë¹„ë™ê¸° ì²˜ë¦¬ì™€ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ê²°í•©í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•í•˜ê¸°

4. **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”**: ORMê³¼ ì›ì‹œ SQLì„ ë¹„êµí•˜ê³ , ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ë°©ë²• ì—°êµ¬í•˜ê¸°

5. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•  ë•Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•˜ëŠ” ì „ëµ ê°œë°œí•˜ê¸° 