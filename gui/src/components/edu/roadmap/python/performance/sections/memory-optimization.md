---

# π“ 10.3 λ©”λ¨λ¦¬ μµμ ν™”

## β… 10.3.1 λ©”λ¨λ¦¬ ν”„λ΅νμΌλ§
1. **`memory_profiler` μ‚¬μ©λ²•**
   - λΌμΈλ³„ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λ¶„μ„
   - λ©”λ¨λ¦¬ λ„μ νƒμ§€
   - μµμ ν™” ν¬μΈνΈ λ°κ²¬

```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    """λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ λ§μ€ ν•¨μ"""
    # λ¦¬μ¤νΈ μ»΄ν”„λ¦¬ν—¨μ… (λΉ„ν¨μ¨μ )
    data = [i ** 2 for i in range(10**6)]
    
    # μ λ„λ μ΄ν„° ν‘ν„μ‹ (ν¨μ¨μ )
    data_gen = (i ** 2 for i in range(10**6))
    
    return sum(data_gen)

# μ‹¤ν–‰
result = memory_intensive_function()
```

## β… 10.3.2 λ©”λ¨λ¦¬ μµμ ν™” κΈ°λ²•
1. **μ λ„λ μ΄ν„° ν™μ©**
2. **μ²­ν¬ λ‹¨μ„ μ²λ¦¬**
3. **μΊμ‹ ν™μ©**

```python
from functools import lru_cache

# μΊμ‹λ¥Ό μ‚¬μ©ν• μµμ ν™”
@lru_cache(maxsize=128)
def fibonacci(n):
    """ν”Όλ³΄λ‚μΉ μμ—΄ κ³„μ‚° (μΊμ‹ ν™μ©)"""
    if n < 2:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# μ²­ν¬ λ‹¨μ„ νμΌ μ²λ¦¬
def process_large_file(filename, chunk_size=1024):
    """λ€μ©λ‰ νμΌ μ²­ν¬ λ‹¨μ„ μ²λ¦¬"""
    with open(filename, 'rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            process_chunk(chunk)

def process_chunk(chunk):
    """μ²­ν¬ λ°μ΄ν„° μ²λ¦¬"""
    pass  # μ‹¤μ  μ²λ¦¬ λ΅μ§ κµ¬ν„
```

## β… 10.3.3 λ©”λ¨λ¦¬ λ„μ λ°©μ§€

νμ΄μ¬μ€ κ°€λΉ„μ§€ μ»¬λ ‰ν„°κ°€ μμ§€λ§, μν™ μ°Έμ΅° λ“±μΌλ΅ μΈν• λ©”λ¨λ¦¬ λ„μκ°€ λ°μƒν•  μ μμµλ‹λ‹¤. μ΄λ¥Ό λ°©μ§€ν•λ” λ°©λ²•μ„ μ•μ•„λ΄…μ‹λ‹¤.

```python
import gc
import weakref

# μ•½ν• μ°Έμ΅° μ‚¬μ© μμ 
class Node:
    def __init__(self, value):
        self.value = value
        self.parent = None
        self.children = []
        
    def add_child(self, child):
        # κ°•ν• μ°Έμ΅° λ€μ‹  μ•½ν• μ°Έμ΅° μ‚¬μ©
        child.parent = weakref.ref(self)
        self.children.append(child)

# κ°€λΉ„μ§€ μ»¬λ ‰μ… κ°•μ  μ‹¤ν–‰
def force_gc():
    # κ°€λΉ„μ§€ μ»¬λ ‰μ… μ‹¤ν–‰ μ „ ν›„ λ©”λ¨λ¦¬ μƒνƒ ν™•μΈ
    before = len(gc.get_objects())
    gc.collect()
    after = len(gc.get_objects())
    print(f"GC μ‹¤ν–‰ κ²°κ³Ό: {before - after}κ° κ°μ²΄ μκ±°")
```

## β… 10.3.4 λ€μ©λ‰ λ°μ΄ν„° μ²λ¦¬ μµμ ν™”

NumPy λ°°μ—΄μ΄λ‚ Pandas DataFrameμ„ μ‚¬μ©ν•  λ• λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ„ μ¤„μ΄λ” λ°©λ²•:

```python
import numpy as np
import pandas as pd

def optimize_numeric_arrays():
    # μΌλ° μ •μ λ°°μ—΄ (64λΉ„νΈ)
    standard_array = np.array([1, 2, 3, 4, 5], dtype=np.int64)
    
    # μµμ ν™”λ μ •μ λ°°μ—΄ (8λΉ„νΈ)
    optimized_array = np.array([1, 2, 3, 4, 5], dtype=np.int8)
    
    print(f"ν‘μ¤€ λ°°μ—΄ λ©”λ¨λ¦¬: {standard_array.nbytes} bytes")
    print(f"μµμ ν™” λ°°μ—΄ λ©”λ¨λ¦¬: {optimized_array.nbytes} bytes")
    print(f"μµμ ν™” λΉ„μ¨: {standard_array.nbytes / optimized_array.nbytes}λ°°")
    
    return optimized_array

def optimize_dataframe():
    # μ›λ³Έ λ°μ΄ν„°ν”„λ μ„
    df = pd.DataFrame({
        'id': np.arange(10000),
        'value': np.random.randn(10000)
    })
    
    # λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ
    original_memory = df.memory_usage(deep=True).sum()
    
    # λ°μ΄ν„° νƒ€μ… μµμ ν™”
    df_optimized = df.copy()
    df_optimized['id'] = df_optimized['id'].astype('int32')
    
    # μµμ ν™” ν›„ λ©”λ¨λ¦¬ μ‚¬μ©λ‰
    optimized_memory = df_optimized.memory_usage(deep=True).sum()
    
    print(f"μ›λ³Έ λ©”λ¨λ¦¬: {original_memory / 1024:.2f} KB")
    print(f"μµμ ν™” ν›„: {optimized_memory / 1024:.2f} KB")
    print(f"μ μ•½: {(original_memory - optimized_memory) / original_memory * 100:.2f}%")
    
    return df_optimized
```

--- 