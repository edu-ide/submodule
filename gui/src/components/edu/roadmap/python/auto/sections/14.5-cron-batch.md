# 14.5 크론 작업 및 배치 스크립트

반복적인 작업을 특정 시간이나 간격으로 자동 실행하는 것은 시스템 관리와 자동화의 핵심입니다. 파이썬을 활용하면 운영체제에 내장된 작업 스케줄러와 연동하거나 독립적인 스케줄링 솔루션을 구현할 수 있습니다.

## ✅ 14.5.1 파이썬 스케줄링 라이브러리

파이썬에서는 `schedule`, `APScheduler` 등의 라이브러리를 사용하여 작업 스케줄링을 구현할 수 있습니다.

```python
import schedule
import time
import logging
import datetime
import os
import sys
from functools import wraps

# 로깅 설정
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("scheduler.log"),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger("task_scheduler")

# 오류 처리 데코레이터
def catch_exceptions(job_func):
    @wraps(job_func)
    def wrapper(*args, **kwargs):
        try:
            return job_func(*args, **kwargs)
        except Exception as e:
            logger.error(f"작업 실행 중 오류 발생: {e}", exc_info=True)
    return wrapper

class TaskScheduler:
    """작업 스케줄링 클래스"""
    
    def __init__(self):
        self.active_jobs = {}
        self.running = False
    
    @catch_exceptions
    def example_task_1(self, name="작업1"):
        """예제 작업 1: 로그 기록"""
        now = datetime.datetime.now()
        logger.info(f"{name} 실행: {now}")
        return now
    
    @catch_exceptions
    def example_task_2(self, base_dir="./data"):
        """예제 작업 2: 오래된 임시 파일 정리"""
        if not os.path.exists(base_dir):
            logger.warning(f"디렉토리가 존재하지 않음: {base_dir}")
            return 0
        
        # 7일 이상 된 파일 삭제
        cutoff = datetime.datetime.now() - datetime.timedelta(days=7)
        count = 0
        
        for root, _, files in os.walk(base_dir):
            for file in files:
                if file.startswith('temp_'):
                    file_path = os.path.join(root, file)
                    file_mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(file_path))
                    
                    if file_mod_time < cutoff:
                        try:
                            os.remove(file_path)
                            count += 1
                            logger.info(f"오래된 파일 삭제: {file_path}")
                        except Exception as e:
                            logger.error(f"파일 삭제 실패 ({file_path}): {e}")
        
        logger.info(f"총 {count}개의 오래된 임시 파일 삭제됨")
        return count
    
    @catch_exceptions
    def example_task_3(self, output_file="system_status.log"):
        """예제 작업 3: 시스템 상태 기록"""
        import psutil
        
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        status = (f"시간: {datetime.datetime.now()}\n"
                 f"CPU 사용률: {cpu_percent}%\n"
                 f"메모리 사용률: {memory.percent}% (사용: {memory.used / 1024 / 1024:.1f} MB, "
                 f"전체: {memory.total / 1024 / 1024:.1f} MB)\n"
                 f"디스크 사용률: {disk.percent}% (사용: {disk.used / 1024 / 1024 / 1024:.1f} GB, "
                 f"전체: {disk.total / 1024 / 1024 / 1024:.1f} GB)\n")
        
        with open(output_file, 'a') as f:
            f.write(status + "-" * 50 + "\n")
        
        logger.info(f"시스템 상태 기록됨: CPU {cpu_percent}%, 메모리 {memory.percent}%, 디스크 {disk.percent}%")
        return {'cpu': cpu_percent, 'memory': memory.percent, 'disk': disk.percent}
    
    def schedule_daily_task(self, task_func, time_str, *args, **kwargs):
        """매일 특정 시간에 실행되는 작업 예약"""
        job = schedule.every().day.at(time_str).do(task_func, *args, **kwargs)
        job_id = f"{task_func.__name__}_daily_{time_str}"
        self.active_jobs[job_id] = job
        logger.info(f"매일 {time_str}에 실행되는 작업 예약됨: {task_func.__name__}")
        return job_id
    
    def schedule_interval_task(self, task_func, interval_minutes, *args, **kwargs):
        """일정 간격으로 실행되는 작업 예약"""
        job = schedule.every(interval_minutes).minutes.do(task_func, *args, **kwargs)
        job_id = f"{task_func.__name__}_interval_{interval_minutes}"
        self.active_jobs[job_id] = job
        logger.info(f"{interval_minutes}분 간격으로 실행되는 작업 예약됨: {task_func.__name__}")
        return job_id
    
    def schedule_weekly_task(self, task_func, day_of_week, time_str, *args, **kwargs):
        """매주 특정 요일, 특정 시간에 실행되는 작업 예약"""
        days = {
            'monday': schedule.every().monday,
            'tuesday': schedule.every().tuesday,
            'wednesday': schedule.every().wednesday,
            'thursday': schedule.every().thursday,
            'friday': schedule.every().friday,
            'saturday': schedule.every().saturday,
            'sunday': schedule.every().sunday
        }
        
        if day_of_week.lower() not in days:
            logger.error(f"잘못된 요일: {day_of_week}")
            return None
        
        job = days[day_of_week.lower()].at(time_str).do(task_func, *args, **kwargs)
        job_id = f"{task_func.__name__}_{day_of_week}_{time_str}"
        self.active_jobs[job_id] = job
        logger.info(f"매주 {day_of_week} {time_str}에 실행되는 작업 예약됨: {task_func.__name__}")
        return job_id
    
    def cancel_task(self, job_id):
        """예약된 작업 취소"""
        if job_id in self.active_jobs:
            schedule.cancel_job(self.active_jobs[job_id])
            del self.active_jobs[job_id]
            logger.info(f"작업 취소됨: {job_id}")
            return True
        else:
            logger.warning(f"작업을 찾을 수 없음: {job_id}")
            return False
    
    def start(self):
        """스케줄러 시작"""
        self.running = True
        logger.info("스케줄러 시작됨")
        
        while self.running:
            schedule.run_pending()
            time.sleep(1)
    
    def stop(self):
        """스케줄러 중지"""
        self.running = False
        logger.info("스케줄러 중지됨")
```

## ✅ 14.5.2 운영체제 작업 스케줄러와 연동

파이썬 스크립트를 운영체제의 작업 스케줄러(Linux의 cron, Windows의 Task Scheduler)와 연동하여 실행할 수 있습니다.

### Linux Cron 작업 생성

```python
import subprocess
import os
import tempfile
import getpass

class CronManager:
    """Linux Cron 작업 관리자"""
    
    @staticmethod
    def list_cron_jobs():
        """현재 사용자의 cron 작업 목록 조회"""
        try:
            result = subprocess.run(['crontab', '-l'], capture_output=True, text=True)
            if result.returncode == 0:
                return result.stdout
            else:
                return "cron 작업이 없거나 오류 발생: " + result.stderr
        except Exception as e:
            return f"cron 목록 조회 실패: {e}"
    
    @staticmethod
    def add_cron_job(schedule_expr, command):
        """
        cron 작업 추가
        schedule_expr: cron 표현식 (예: '0 5 * * *' - 매일 오전 5시)
        command: 실행할 명령어
        """
        try:
            # 현재 cron 작업 목록 가져오기
            current_crontab = subprocess.run(['crontab', '-l'], capture_output=True, text=True)
            
            # 임시 파일 생성
            fd, path = tempfile.mkstemp()
            with os.fdopen(fd, 'w') as f:
                # 기존 cron 작업이 있으면 복사
                if current_crontab.returncode == 0:
                    f.write(current_crontab.stdout)
                
                # 새 작업 추가
                f.write(f"{schedule_expr} {command}\n")
            
            # 새 crontab 적용
            result = subprocess.run(['crontab', path], capture_output=True, text=True)
            os.unlink(path)  # 임시 파일 삭제
            
            if result.returncode == 0:
                return True, "cron 작업이 성공적으로 추가되었습니다."
            else:
                return False, f"cron 작업 추가 실패: {result.stderr}"
        except Exception as e:
            return False, f"cron 작업 추가 중 오류 발생: {e}"
    
    @staticmethod
    def remove_cron_job(command_pattern):
        """
        특정 패턴을 포함하는 cron 작업 제거
        command_pattern: 제거할 명령어의 일부
        """
        try:
            # 현재 cron 작업 목록 가져오기
            current_crontab = subprocess.run(['crontab', '-l'], capture_output=True, text=True)
            
            if current_crontab.returncode != 0:
                return False, "현재 cron 작업이 없거나 조회 실패"
            
            # 명령어 패턴과 일치하지 않는 작업만 유지
            lines = current_crontab.stdout.splitlines()
            new_lines = [line for line in lines if command_pattern not in line]
            
            # 제거된 작업이 없으면
            if len(lines) == len(new_lines):
                return False, f"패턴 '{command_pattern}'과 일치하는 cron 작업이 없습니다."
            
            # 임시 파일 생성
            fd, path = tempfile.mkstemp()
            with os.fdopen(fd, 'w') as f:
                f.write('\n'.join(new_lines) + '\n')
            
            # 새 crontab 적용
            result = subprocess.run(['crontab', path], capture_output=True, text=True)
            os.unlink(path)  # 임시 파일 삭제
            
            if result.returncode == 0:
                return True, f"{len(lines) - len(new_lines)}개의 cron 작업이 삭제되었습니다."
            else:
                return False, f"cron 작업 삭제 실패: {result.stderr}"
        except Exception as e:
            return False, f"cron 작업 삭제 중 오류 발생: {e}"
    
    @staticmethod
    def create_python_cron_job(schedule_expr, script_path, args=None, log_file=None):
        """
        파이썬 스크립트를 실행하는 cron 작업 생성
        schedule_expr: cron 표현식 (예: '0 5 * * *' - 매일 오전 5시)
        script_path: 파이썬 스크립트 경로
        args: 명령줄 인수 (선택사항)
        log_file: 로그 파일 경로 (선택사항)
        """
        # 파이썬 인터프리터 경로
        python_path = sys.executable
        
        # 명령어 구성
        command = f"{python_path} {script_path}"
        if args:
            command += f" {args}"
        
        # 로그 파일 지정
        if log_file:
            command += f" >> {log_file} 2>&1"
        
        return CronManager.add_cron_job(schedule_expr, command)
```

### Windows 작업 스케줄러 사용

```python
import subprocess
import os
import sys
import datetime

class WindowsTaskScheduler:
    """Windows 작업 스케줄러 관리자"""
    
    @staticmethod
    def list_tasks(folder="/"):
        """
        작업 스케줄러의 작업 목록 조회
        folder: 작업 폴더 (기본값: 루트 폴더)
        """
        try:
            result = subprocess.run(['schtasks', '/query', '/fo', 'LIST', '/v', '/tn', folder], 
                                   capture_output=True, text=True)
            return result.stdout
        except Exception as e:
            return f"작업 목록 조회 실패: {e}"
    
    @staticmethod
    def create_daily_task(task_name, script_path, start_time, args=None):
        """
        매일 실행되는 작업 생성
        task_name: 작업 이름
        script_path: 실행할 파이썬 스크립트 경로
        start_time: 시작 시간 (HH:MM 형식)
        args: 명령줄 인수 (선택사항)
        """
        # 파이썬 인터프리터 경로
        python_path = sys.executable
        
        # 명령어 구성
        command = f'"{python_path}" "{script_path}"'
        if args:
            command += f" {args}"
        
        try:
            # 작업 생성
            cmd = [
                'schtasks', '/create', '/tn', task_name,
                '/tr', command,
                '/sc', 'DAILY',
                '/st', start_time,
                '/f'  # 기존 작업 덮어쓰기
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                return True, f"작업 '{task_name}'이(가) 성공적으로 생성되었습니다."
            else:
                return False, f"작업 생성 실패: {result.stderr}"
        except Exception as e:
            return False, f"작업 생성 중 오류 발생: {e}"
    
    @staticmethod
    def create_weekly_task(task_name, script_path, day_of_week, start_time, args=None):
        """
        매주 특정 요일에 실행되는 작업 생성
        task_name: 작업 이름
        script_path: 실행할 파이썬 스크립트 경로
        day_of_week: 요일 (MON, TUE, WED, THU, FRI, SAT, SUN)
        start_time: 시작 시간 (HH:MM 형식)
        args: 명령줄 인수 (선택사항)
        """
        # 파이썬 인터프리터 경로
        python_path = sys.executable
        
        # 명령어 구성
        command = f'"{python_path}" "{script_path}"'
        if args:
            command += f" {args}"
        
        try:
            # 작업 생성
            cmd = [
                'schtasks', '/create', '/tn', task_name,
                '/tr', command,
                '/sc', 'WEEKLY',
                '/d', day_of_week,
                '/st', start_time,
                '/f'  # 기존 작업 덮어쓰기
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                return True, f"작업 '{task_name}'이(가) 성공적으로 생성되었습니다."
            else:
                return False, f"작업 생성 실패: {result.stderr}"
        except Exception as e:
            return False, f"작업 생성 중 오류 발생: {e}"
    
    @staticmethod
    def delete_task(task_name):
        """
        작업 삭제
        task_name: 삭제할 작업 이름
        """
        try:
            result = subprocess.run(['schtasks', '/delete', '/tn', task_name, '/f'], 
                                   capture_output=True, text=True)
            
            if result.returncode == 0:
                return True, f"작업 '{task_name}'이(가) 성공적으로 삭제되었습니다."
            else:
                return False, f"작업 삭제 실패: {result.stderr}"
        except Exception as e:
            return False, f"작업 삭제 중 오류 발생: {e}"
```

## ✅ 14.5.3 배치 처리와 병렬 실행

대량의 데이터나 작업을 효율적으로 처리하기 위한 배치 처리 및 병렬 실행 기법입니다.

```python
import os
import time
import logging
import concurrent.futures
import multiprocessing
import queue
from functools import partial

class BatchProcessor:
    """배치 처리 및 병렬 실행 클래스"""
    
    def __init__(self, max_workers=None, use_multiprocessing=False):
        """
        초기화
        max_workers: 최대 작업자 수 (기본값: CPU 코어 수)
        use_multiprocessing: 멀티프로세싱 사용 여부 (기본값: False, 스레드 풀 사용)
        """
        self.max_workers = max_workers or multiprocessing.cpu_count()
        self.use_multiprocessing = use_multiprocessing
        
        # 로깅 설정
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler("batch_processor.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("batch_processor")
    
    def process_batch(self, items, process_func, batch_size=100, *args, **kwargs):
        """
        배치 단위로 항목 처리
        items: 처리할 항목 리스트
        process_func: 각 항목을 처리하는 함수 (항목을 첫 번째 인수로 받음)
        batch_size: 배치 크기
        *args, **kwargs: process_func에 전달할 추가 인수
        """
        results = []
        total_items = len(items)
        processed = 0
        
        # 배치 처리
        for i in range(0, total_items, batch_size):
            batch = items[i:i+batch_size]
            batch_results = []
            
            # 각 항목 처리
            for item in batch:
                try:
                    result = process_func(item, *args, **kwargs)
                    batch_results.append(result)
                except Exception as e:
                    self.logger.error(f"항목 처리 중 오류 발생: {e}", exc_info=True)
                    batch_results.append(None)
            
            results.extend(batch_results)
            processed += len(batch)
            self.logger.info(f"진행 상황: {processed}/{total_items} ({processed/total_items*100:.1f}%)")
        
        return results
    
    def process_parallel(self, items, process_func, *args, **kwargs):
        """
        병렬로 항목 처리
        items: 처리할 항목 리스트
        process_func: 각 항목을 처리하는 함수 (항목을 첫 번째 인수로 받음)
        *args, **kwargs: process_func에 전달할 추가 인수
        """
        # partial 함수로 추가 인수 바인딩
        worker_func = partial(self._worker_wrapper, process_func, *args, **kwargs)
        
        # 병렬 처리
        executor_class = concurrent.futures.ProcessPoolExecutor if self.use_multiprocessing else concurrent.futures.ThreadPoolExecutor
        
        start_time = time.time()
        results = []
        
        with executor_class(max_workers=self.max_workers) as executor:
            # 작업 제출
            future_to_item = {executor.submit(worker_func, item): item for item in items}
            
            # 결과 수집
            for i, future in enumerate(concurrent.futures.as_completed(future_to_item)):
                item = future_to_item[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    self.logger.error(f"항목 {item} 처리 중 오류 발생: {e}", exc_info=True)
                    results.append(None)
                
                # 진행 상황 로깅
                if (i + 1) % 10 == 0 or (i + 1) == len(items):
                    self.logger.info(f"진행 상황: {i+1}/{len(items)} ({(i+1)/len(items)*100:.1f}%)")
        
        elapsed_time = time.time() - start_time
        self.logger.info(f"병렬 처리 완료: {len(items)}개 항목, 소요 시간: {elapsed_time:.2f}초")
        
        return results
    
    def _worker_wrapper(self, func, *args, **kwargs):
        """작업자 래퍼 함수 (예외 처리 포함)"""
        try:
            return func(*args, **kwargs)
        except Exception as e:
            self.logger.error(f"작업자 함수 실행 중 오류 발생: {e}", exc_info=True)
            raise
    
    def process_files(self, directory, file_func, file_pattern=None, recursive=False, *args, **kwargs):
        """
        디렉토리 내의 파일 처리
        directory: 처리할 파일이 있는 디렉토리
        file_func: 각 파일을 처리하는 함수 (파일 경로를 첫 번째 인수로 받음)
        file_pattern: 처리할 파일 패턴 (예: '*.txt')
        recursive: 하위 디렉토리 포함 여부
        *args, **kwargs: file_func에 전달할 추가 인수
        """
        import fnmatch
        
        file_paths = []
        
        # 파일 수집
        if recursive:
            for root, _, files in os.walk(directory):
                for file in files:
                    if file_pattern is None or fnmatch.fnmatch(file, file_pattern):
                        file_paths.append(os.path.join(root, file))
        else:
            for file in os.listdir(directory):
                file_path = os.path.join(directory, file)
                if os.path.isfile(file_path) and (file_pattern is None or fnmatch.fnmatch(file, file_pattern)):
                    file_paths.append(file_path)
        
        self.logger.info(f"처리할 파일 수: {len(file_paths)}")
        
        # 병렬 처리
        return self.process_parallel(file_paths, file_func, *args, **kwargs)
```

## ✅ 14.5.4 작업 큐와 워커 패턴

작업 큐와 워커 패턴은 분산 작업 처리에 유용한 아키텍처입니다. 이 패턴을 사용하면 작업 생성자(producer)와 작업 처리자(consumer)를 분리할 수 있습니다.

```python
import queue
import threading
import time
import logging
import uuid
from datetime import datetime
import json
import os

class TaskQueue:
    """작업 큐 시스템"""
    
    def __init__(self, num_workers=2, queue_size=100):
        """
        초기화
        num_workers: 작업자 수
        queue_size: 큐 크기 (최대 대기 작업 수)
        """
        # 작업 큐
        self.task_queue = queue.Queue(maxsize=queue_size)
        
        # 작업자 스레드
        self.workers = []
        self.num_workers = num_workers
        
        # 작업 결과 저장
        self.results = {}
        self.results_lock = threading.Lock()
        
        # 실행 상태
        self.running = False
        
        # 로깅 설정
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler("task_queue.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger("task_queue")
    
    def start(self):
        """작업 큐 시스템 시작"""
        if self.running:
            self.logger.warning("작업 큐 시스템이 이미 실행 중입니다.")
            return
        
        self.running = True
        
        # 작업자 스레드 생성 및 시작
        for i in range(self.num_workers):
            worker = threading.Thread(target=self._worker_loop, args=(i,), daemon=True)
            worker.start()
            self.workers.append(worker)
        
        self.logger.info(f"작업 큐 시스템 시작됨 (작업자 {self.num_workers}개)")
    
    def stop(self):
        """작업 큐 시스템 중지"""
        if not self.running:
            self.logger.warning("작업 큐 시스템이 실행 중이 아닙니다.")
            return
        
        self.running = False
        
        # 남은 작업 처리 대기
        self.task_queue.join()
        
        self.logger.info("작업 큐 시스템 중지됨")
    
    def add_task(self, task_func, *args, **kwargs):
        """
        작업 추가
        task_func: 실행할 함수
        *args, **kwargs: 함수에 전달할 인수
        """
        task_id = str(uuid.uuid4())
        task = {
            'id': task_id,
            'func': task_func,
            'args': args,
            'kwargs': kwargs,
            'created_at': datetime.now().isoformat()
        }
        
        try:
            self.task_queue.put(task)
            self.logger.info(f"작업 추가됨: {task_id}")
            return task_id
        except queue.Full:
            self.logger.error("작업 큐가 가득 찼습니다.")
            return None
    
    def get_result(self, task_id, timeout=None):
        """
        작업 결과 조회
        task_id: 작업 ID
        timeout: 대기 시간 (초) - None이면 무기한 대기
        """
        start_time = time.time()
        
        while timeout is None or time.time() - start_time < timeout:
            with self.results_lock:
                if task_id in self.results:
                    result = self.results[task_id]
                    # 결과 조회 후 삭제 (메모리 관리)
                    del self.results[task_id]
                    return result
            
            time.sleep(0.1)
        
        return {'status': 'timeout', 'error': '작업 결과 대기 시간 초과'}
    
    def _worker_loop(self, worker_id):
        """작업자 루프"""
        self.logger.info(f"작업자 {worker_id} 시작됨")
        
        while self.running:
            try:
                # 작업 가져오기
                task = self.task_queue.get(timeout=1)
                
                start_time = time.time()
                task_id = task['id']
                
                try:
                    # 작업 실행
                    self.logger.info(f"작업 {task_id} 실행 중 (작업자 {worker_id})")
                    result = task['func'](*task['args'], **task['kwargs'])
                    
                    # 결과 저장
                    with self.results_lock:
                        self.results[task_id] = {
                            'status': 'completed',
                            'result': result,
                            'execution_time': time.time() - start_time
                        }
                    
                    self.logger.info(f"작업 {task_id} 완료 (작업자 {worker_id})")
                
                except Exception as e:
                    # 오류 저장
                    self.logger.error(f"작업 {task_id} 실행 중 오류 발생: {e}", exc_info=True)
                    
                    with self.results_lock:
                        self.results[task_id] = {
                            'status': 'error',
                            'error': str(e),
                            'execution_time': time.time() - start_time
                        }
                
                finally:
                    # 작업 완료 표시
                    self.task_queue.task_done()
            
            except queue.Empty:
                # 타임아웃 (정상)
                pass
            except Exception as e:
                self.logger.error(f"작업자 {worker_id} 오류: {e}", exc_info=True)
        
        self.logger.info(f"작업자 {worker_id} 종료됨")
    
    def persist_queue(self, file_path):
        """작업 큐 상태 저장"""
        # 현재 큐의 작업을 목록으로 변환
        tasks = []
        temp_queue = queue.Queue()
        
        try:
            # 큐의 모든 작업 추출
            while not self.task_queue.empty():
                task = self.task_queue.get()
                tasks.append({
                    'id': task['id'],
                    'created_at': task['created_at'],
                    # 함수 객체는 직렬화할 수 없으므로 이름으로 저장
                    'func_name': task['func'].__name__,
                    # args와 kwargs는 직렬화 가능한 객체만 저장
                    'args': task['args'],
                    'kwargs': task['kwargs']
                })
                temp_queue.put(task)
            
            # 작업을 다시 큐에 넣기
            while not temp_queue.empty():
                self.task_queue.put(temp_queue.get())
            
            # 파일에 저장
            with open(file_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'pending_tasks': tasks,
                    'num_workers': self.num_workers
                }, f, indent=2)
            
            self.logger.info(f"작업 큐 상태가 {file_path}에 저장되었습니다.")
            return True
        
        except Exception as e:
            self.logger.error(f"작업 큐 상태 저장 실패: {e}", exc_info=True)
            return False
    
    def get_queue_stats(self):
        """작업 큐 통계 조회"""
        return {
            'pending_tasks': self.task_queue.qsize(),
            'num_workers': self.num_workers,
            'num_results': len(self.results),
            'running': self.running
        }
```

작업 스케줄링과 배치 처리는 시스템 자동화의 핵심 요소로, 다양한 비즈니스 및 기술 도메인에서 활용됩니다. 다음 섹션에서는 이러한 개념을 실제 프로젝트에 적용하는 방법을 살펴보겠습니다. 